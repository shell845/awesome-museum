{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Awesome Museum\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project collects and presents information about museums (US only at current stage, may extend to global in next pharse), including museum categories, locations, ratings and more.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import boto3\n",
    "import configparser\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.7'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read configuration files\n",
    "config = configparser.ConfigParser()\n",
    "config.read('aws.cfg')\n",
    "\n",
    "# AWS access key\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['KEYS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['KEYS']['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "# AWS role\n",
    "IAM = config['IAM_ROLE']['ARN']\n",
    "\n",
    "# Redshift cluster\n",
    "rs_host=config['CLUSTER']['HOST']\n",
    "rs_dbname=config['CLUSTER']['DB_NAME']\n",
    "rs_user=config['CLUSTER']['DB_USER']\n",
    "rs_password=config['CLUSTER']['DB_PASSWORD']\n",
    "rs_port=config['CLUSTER']['DB_PORT']\n",
    "\n",
    "# S3\n",
    "MUSEUM_DATA_RAW = config['S3']['MUSEUM_DATA']             # csv file\n",
    "MUSEUM_DATA = config['S3']['MUSEUM_DATA_OUTPUT']          # parquet file output by Spark\n",
    "MUSEUM_DATA_S3 = config['S3']['MUSEUM_DATA_S3']  \n",
    "\n",
    "WEATHER_DATA_RAW = config['S3']['WEATHER_DATA']           # csv file\n",
    "WEATHER_DATA = config['S3']['WEATHER_DATA_OUTPUT']        # parquet file output by Spark\n",
    "WEATHER_DATA_S3 = config['S3']['WEATHER_DATA_S3']\n",
    "\n",
    "CATEGORY_BUCKET = config['S3']['CATEGORY_BUCKET'] \n",
    "CATEGORY_KEY = config['S3']['CATEGORY_KEY']\n",
    "CATEGORY_OUTPUT_KEY = config['S3']['CATEGORY_OUTPUT_KEY']\n",
    "CATEGORY_DATA = config['S3']['CATEGORY_DATA']             # json file\n",
    "CATEGORY_DATA_S3 = config['S3']['CATEGORY_DATA_S3']\n",
    "\n",
    "TRAVELER_BUCKET = config['S3']['TRAVELER_BUCKET'] \n",
    "TRAVELER_KEY = config['S3']['TRAVELER_KEY']\n",
    "TRAVELER_OUTPUT_KEY = config['S3']['TRAVELER_OUTPUT_KEY']\n",
    "TRAVELER_DATA = config['S3']['TRAVELER_DATA']             # json file\n",
    "TRAVELER_DATA_S3 = config['S3']['TRAVELER_DATA_S3']\n",
    "\n",
    "S3_REGION = config['S3']['REGION']\n",
    "\n",
    "# Country and weather date\n",
    "COUNTRY = config['FILTER']['COUNTRY']\n",
    "WEATHER_DATE = config['FILTER']['DATE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Gather information for museums. Redshift and Spark are used for this project.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Data are collected from Kaggle and Tripadvisor and are uploaded to AWS S3 s3://udacity-dend-shell845/museum-data/\n",
    "\n",
    "museum overall summary of museums extracted from Tripadvisor. In csv format.\n",
    "\n",
    "Address, Description, FeatureCount, Fee, Langtitude, Latitude, LengthOfVisit, MuseumName, PhoneNum, Rank, Rating, ReviewCount,TotalThingsToDo\n",
    "\n",
    "category categories of museums, e.g. art museum, history museum, science museum etc. In json format.\n",
    "\n",
    "{'museum': ['museum type 1','museum type 2', â€¦]}\n",
    "\n",
    "rating how many ratings did the museums receive and what are the ratings. In json format.\n",
    "\n",
    "{'museum': ['Excellent','Very good','Average','Poor','Terrible']}\n",
    "\n",
    "traveler how the travers travel. In json format.\n",
    "\n",
    "{'museum': ['Families','Couples','Solo','Business','Friends']}\n",
    "\n",
    "weather average tempature of the cities where the museums are located. In csv format.\n",
    "\n",
    "dt,AverageTemperature,AverageTemperatureUncertainty,City,Country,Latitude,Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create spark session\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.awsAccessKeyId\", os.environ['AWS_ACCESS_KEY_ID']) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.awsSecretAccessKey\", os.environ['AWS_SECRET_ACCESS_KEY']) \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process museum data start...\n",
      "Process museum data complete\n"
     ]
    }
   ],
   "source": [
    "# process museum raw data  \n",
    "process_museum_data(spark, MUSEUM_DATA_RAW, MUSEUM_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process weather data start...\n",
      "Process weather data complete\n"
     ]
    }
   ],
   "source": [
    "# process weather raw data\n",
    "process_weather_data(spark, WEATHER_DATA_RAW, WEATHER_DATA, COUNTRY, WEATHER_SINCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process category data start\n",
      "Process category data complete\n"
     ]
    }
   ],
   "source": [
    "# process category raw data\n",
    "process_category_data(CATEGORY_BUCKET, CATEGORY_KEY, CATEGORY_OUTPUT_KEY, S3_REGION, os.environ['AWS_ACCESS_KEY_ID'], os.environ['AWS_SECRET_ACCESS_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process traveler data start\n",
      "Process traveler data complete\n"
     ]
    }
   ],
   "source": [
    "# process traveler raw data\n",
    "process_traveler_data(TRAVELER_BUCKET, TRAVELER_KEY, TRAVELER_OUTPUT_KEY, S3_REGION, os.environ['AWS_ACCESS_KEY_ID'], os.environ['AWS_SECRET_ACCESS_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# completed in step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connect Redshift start\n",
      "Connect Redshift complete\n"
     ]
    }
   ],
   "source": [
    "# connect to redshift\n",
    "def create_redshift_connection():\n",
    "    \"\"\"\n",
    "        Create Redshift connection\n",
    "        and return the connection\n",
    "    \"\"\"\n",
    "    print(\"Connect Redshift start\")\n",
    "\n",
    "    conn = psycopg2.connect(f\"host={rs_host} dbname={rs_dbname} user={rs_user} password={rs_password} port={rs_port}\")\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    print(\"Connect Redshift complete\")\n",
    "    return conn, cur\n",
    "\n",
    "conn, cur = create_redshift_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'psycopg2.extensions.connection'>\n",
      "<class 'psycopg2.extensions.cursor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(conn))\n",
    "print(type(cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "drop_tables(conn, cur, drop_table_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete create tables\n"
     ]
    }
   ],
   "source": [
    "create_tables(conn, cur, create_table_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "arn = \"'\" + IAM + \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy parquet data from S3 to Redshift staging complete\n"
     ]
    }
   ],
   "source": [
    "staging_museum_sql = staging_parquet_copy.format(table_name='staging_museum', s3_bucket=MUSEUM_DATA_S3, arn_role=arn)\n",
    "staging_parquet_data(cur, conn, [staging_museum_sql])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy parquet data from S3 to Redshift staging complete\n"
     ]
    }
   ],
   "source": [
    "staging_weather_sql = staging_parquet_copy.format(table_name='staging_weather', s3_bucket=WEATHER_DATA_S3, arn_role=arn)\n",
    "staging_parquet_data(cur, conn, [staging_weather_sql])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2013, 3, 1), 1.323, 'Chicago', 'United States'),\n",
       " (datetime.date(2012, 12, 1), 2.791, 'Roseville', 'United States'),\n",
       " (datetime.date(2013, 5, 1), 14.543, 'Roseville', 'United States'),\n",
       " (datetime.date(2013, 6, 1), 19.446, 'Roseville', 'United States'),\n",
       " (datetime.date(2013, 2, 1), 4.662, 'Roseville', 'United States'),\n",
       " (datetime.date(2013, 7, 1), 23.589, 'Roseville', 'United States'),\n",
       " (datetime.date(2013, 8, 1), 22.23, 'Chicago', 'United States'),\n",
       " (datetime.date(2013, 1, 1), 1.056, 'Chicago', 'United States'),\n",
       " (datetime.date(2013, 7, 1), 21.914, 'Chicago', 'United States'),\n",
       " (datetime.date(2013, 5, 1), 13.734, 'Chicago', 'United States')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SELECT * FROM staging_weather LIMIT 10;\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy json data from S3 to Redshift staging complete\n"
     ]
    }
   ],
   "source": [
    "staging_category_sql = staging_json_copy.format(table_name='staging_category', s3_bucket=CATEGORY_DATA_S3, arn_role=arn)\n",
    "staging_json_data(cur, conn, [staging_category_sql])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# cur.execute(\"DELETE FROM staging_traveler;\")\n",
    "# cur.execute(\"DELETE FROM city;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy json data from S3 to Redshift staging complete\n"
     ]
    }
   ],
   "source": [
    "staging_traveler_sql = staging_json_copy.format(table_name='staging_traveler', s3_bucket=TRAVELER_DATA_S3, arn_role=arn)\n",
    "staging_json_data(cur, conn, [staging_traveler_sql]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gettysburg Heritage Center', 'History Museums'),\n",
       " ('Hudson River Museum', 'Specialty Museums'),\n",
       " ('The Aurora Ice Museum', 'Specialty Museums'),\n",
       " ('Chrysler Museum of Art', 'Art Museums'),\n",
       " ('Pink Palace Museum', 'History Museums')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"select * from staging_category limit 5;\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gettysburg Heritage Center', 'families', 88),\n",
       " ('Gettysburg Heritage Center', 'couples', 86),\n",
       " ('Gettysburg Heritage Center', 'solo', 17),\n",
       " ('Gettysburg Heritage Center', 'business', 2),\n",
       " ('Gettysburg Heritage Center', 'friends', 33),\n",
       " ('Hudson River Museum', 'families', 25),\n",
       " ('Hudson River Museum', 'couples', 22),\n",
       " ('Hudson River Museum', 'solo', 2),\n",
       " ('Hudson River Museum', 'business', 4),\n",
       " ('Hudson River Museum', 'friends', 15)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"select * from staging_traveler limit 10;\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check - ['\\n    SELECT COUNT(*) FROM staging_category\\n', '\\n    SELECT COUNT(*) FROM staging_traveler\\n', '\\n    SELECT COUNT(*) FROM staging_weather\\n', '\\n    SELECT COUNT(*) FROM staging_museum\\n']\n",
      "Running \n",
      "    SELECT COUNT(*) FROM staging_category\n",
      "\n",
      "    1007\n",
      "Running \n",
      "    SELECT COUNT(*) FROM staging_traveler\n",
      "\n",
      "    5035\n",
      "Running \n",
      "    SELECT COUNT(*) FROM staging_weather\n",
      "\n",
      "    24\n",
      "Running \n",
      "    SELECT COUNT(*) FROM staging_museum\n",
      "\n",
      "    11\n"
     ]
    }
   ],
   "source": [
    "# data quality check on staging tables\n",
    "data_quality_check(cur, conn, select_count_staging_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete traveler table\n"
     ]
    }
   ],
   "source": [
    "# Transform traveler table\n",
    "transform_traveler(cur, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'families'), (2, 'couples'), (3, 'solo'), (4, 'business'), (5, 'friends')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"select * from traveler limit 5;\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete city table\n"
     ]
    }
   ],
   "source": [
    "# transform city table\n",
    "transform_city(cur, conn, city_table_insert, COUNTRY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 'Denver', 'United States'),\n",
       " (13, 'New York City', 'United States'),\n",
       " (6, 'Boston', 'United States'),\n",
       " (8, 'Chicago', 'United States'),\n",
       " (15, 'New Orleans', 'United States')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"select * from city limit 5;\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete weather table\n"
     ]
    }
   ],
   "source": [
    "# transform weather table\n",
    "transform_weather(cur, conn, weather_table_insert, WEATHER_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, datetime.date(2012, 10, 1), 12.229)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"select * from weather limit 5;\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete category table\n"
     ]
    }
   ],
   "source": [
    "# transform category table\n",
    "\n",
    "transform_category(cur, conn, category_table_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 'Specialty Museums'),\n",
       " (7, 'Historic Walking Areas'),\n",
       " (11, 'Natural History Museums'),\n",
       " (15, 'Points of Interest & Landmarks'),\n",
       " (19, 'Military Museums')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"select * from category limit 5;\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete museum table\n"
     ]
    }
   ],
   "source": [
    "# transform museum table\n",
    "transform_museum(cur, conn, museum_table_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10,\n",
       "  'American Museum of Natural History',\n",
       "  11,\n",
       "  '79th Street and Central Park West, New York City, NY 10024',\n",
       "  1,\n",
       "  4.5,\n",
       "  'solo'),\n",
       " (12,\n",
       "  'The Metropolitan Museum of Art',\n",
       "  15,\n",
       "  '1000 5th Ave, New York City, NY 10028-0198',\n",
       "  1,\n",
       "  5.0,\n",
       "  'solo'),\n",
       " (2,\n",
       "  'The National 9/11 Memorial & Museum',\n",
       "  3,\n",
       "  '180 Greenwich St, World Trade Center, New York City, NY 10007-0089',\n",
       "  1,\n",
       "  4.5,\n",
       "  'solo')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"select * from museum limit 3;\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete museum_fact table\n"
     ]
    }
   ],
   "source": [
    "# transform museum fact table\n",
    "transform_museum_fact(cur, conn, museum_fact_table_insert, WEATHER_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 2, 3, 1, 4.5, None, 3, datetime.date(2012, 10, 1)),\n",
       " (2, 10, 11, 1, 4.5, None, 3, datetime.date(2012, 10, 1)),\n",
       " (4, 12, 15, 1, 5.0, None, 3, datetime.date(2012, 10, 1)),\n",
       " (8, 14, 19, 3, 5.0, None, 3, datetime.date(2012, 10, 1)),\n",
       " (7, 1, 1, 7, 4.5, None, 3, datetime.date(2012, 10, 1))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"select * from museum_fact limit 5;\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check - ['\\n    SELECT COUNT(*) FROM staging_category\\n', '\\n    SELECT COUNT(*) FROM staging_traveler\\n', '\\n    SELECT COUNT(*) FROM staging_weather\\n', '\\n    SELECT COUNT(*) FROM staging_museum\\n']\n",
      "Running \n",
      "    SELECT COUNT(*) FROM staging_category\n",
      "\n",
      "    2014\n",
      "Running \n",
      "    SELECT COUNT(*) FROM staging_traveler\n",
      "\n",
      "    1007\n",
      "Running \n",
      "    SELECT COUNT(*) FROM staging_weather\n",
      "\n",
      "    24\n",
      "Running \n",
      "    SELECT COUNT(*) FROM staging_museum\n",
      "\n",
      "    11\n"
     ]
    }
   ],
   "source": [
    "data_quality_check(cur, conn, select_count_staging_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check - ['\\n    SELECT COUNT(*) FROM city\\n', '\\n    SELECT COUNT(*) FROM category\\n', '\\n    SELECT COUNT(*) FROM traveler\\n', '\\n    SELECT COUNT(*) FROM weather\\n', '\\n    SELECT COUNT(*) FROM museum\\n', '\\n    SELECT COUNT(*) FROM museum_fact\\n']\n",
      "Running \n",
      "    SELECT COUNT(*) FROM city\n",
      "\n",
      "    6\n",
      "Running \n",
      "    SELECT COUNT(*) FROM category\n",
      "\n",
      "    42\n",
      "Running \n",
      "    SELECT COUNT(*) FROM traveler\n",
      "\n",
      "    5\n",
      "Running \n",
      "    SELECT COUNT(*) FROM weather\n",
      "\n",
      "    1\n",
      "Running \n",
      "    SELECT COUNT(*) FROM museum\n",
      "\n",
      "    10\n",
      "Running \n",
      "    SELECT COUNT(*) FROM museum_fact\n",
      "\n",
      "    10\n"
     ]
    }
   ],
   "source": [
    "data_quality_check(cur, conn, select_count_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awesome-museum ETL complete\n"
     ]
    }
   ],
   "source": [
    "print(\"awesome-museum ETL complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
